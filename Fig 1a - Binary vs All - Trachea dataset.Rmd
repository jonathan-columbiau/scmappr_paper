---
title: "Fig 1a - Binary vs All - Trachea dataset"
author: "Jonathan Algoo"
date: "2023-11-06"
output: html_document
---

Fig 1a - Using marker genes that differentiate two cell classes > marker genes that differentiate all cell classes, just try training normal ML classifiers using consensus approach on 1-vs-1 vs marker genes identified for 1-vs-all

Load trachea seurat obj from Tabula Muris dataset
```{r}
library(readr)
library(rsample)
annotations <- read.csv("../scmappr_paper_datasets/annotations_facs.csv") %>% dplyr::filter(tissue == "Marrow")
marrow_ge <- read.csv("../scmappr_paper_datasets/FACS/Marrow-counts.csv")
rownames(marrow_ge) <- marrow_ge$X
marrow_ge %<>% select(-X)
marrow_cell_ids <- marrow_ge %>% colnames()
annotations <- annotations[match(marrow_ge %>% colnames(),annotations$cell),]
celltype_anno <- annotations$cluster.ids
#remove cells with na anno
na_cells <- which(is.na(celltype_anno))
celltype_anno <- celltype_anno[-na_cells]
annotations <- annotations[-na_cells,]
#subset marrow_ge to only include non-na anno
marrow_ge <- marrow_ge[,-na_cells]
#write bpcells for future use?
```
Convenience function for reading FACS-formatted TM files to bpcells in one command? 

```{r}
#split 80/20 train/test
#get testing and training set in df form
marrow_ge <- t(marrow_ge) %>% as.data.frame()
marrow_ge$cluster.ids <- annotations$cluster.ids
splits <- initial_split(marrow_ge, prop = .80, strata = cluster.ids, pool = 0)
test.set <- splits %>% testing() 
train.set <- splits %>% training()
test.set <- test.set %>% select(-cluster.ids)
train.set <- train.set %>% select(-cluster.ids)
annotations.train.set <- annotations[match(rownames(train.set),annotations$cell),]
annotations.test.set <- annotations[match(rownames(test.set),annotations$cell),]

```

```{r}
train.set.bp <- train.set %>% t() %>% as("Matrix") %>% as("dgCMatrix") %>% as("IterableMatrix")
test.set.bp <- test.set %>% t() %>% as("Matrix") %>% as("dgCMatrix") %>% as("IterableMatrix")

```


```{r}
tree <- CreateEqualTree(annotations.train.set$cluster.ids)
#only sampled 100 cells per class bc small # cells in many cell classes

pairwise_markers <- FindMarkerGenes(ref_bpcells = train.set.bp, tree = tree, ref_metadata = annotations.train.set,metadata_cluster_column = "cluster.ids",n_cells_sampled = 100,metadata_cell_label_column = "cell")

```
Pairwise analysis 
```{r}
#use getmodels function to create models, then subset to only include rf for this analysis
pairwise_models <- GetModels(pairwise_markers, train.set.bp, annotations.train.set, tree, "cluster.ids", "cell", n_cells_sampled = 100, models_to_include = "elastic_net")
#classify test set just using rf model
#for each cell, choose the class with highest # wins (set prop_max_threshold to 0 to only choose the winningmost irrespective of other class scores for each cell)
pairwise_classifications <- Classify(test.set.bp, models = pairwise_models, tree_struc = tree, prop_max_threshold = 0)
ground_truth_cluster_ids <- annotations.test.set$cluster.ids 
names(ground_truth_cluster_ids) <- annotations.test.set$cell
proportion_tied <- sum(pairwise_classifications == "Broadclass") / length(pairwise_classifications)
tied_obs <- which(pairwise_classifications == "Broadclass")
no_tie_cluster_ids <- ground_truth_cluster_ids[-tied_obs]
no_tie_predicted_ids <- pairwise_classifications[-tied_obs]
proportion_accurate_no_tie <- which(no_tie_predicted_ids == no_tie_cluster_ids) %>% length() / length(no_tie_cluster_ids)
proportion_accurate_no_tie
```



One vs All Analysis 
```{r}
#as done for pairwise marker gene determination, for all class marker gene determination,
#1) Normalize reference atlas by reads-per-cell
all_markers_ds <- multiply_cols(train.set.bp, 1/Matrix::colSums(train.set.bp))
#2) Log normalization
all_markers_ds <- log1p(all_markers_ds * 10000) # Log normalization

all_class_markers <- marker_features(mat = all_markers_ds, groups = annotations.train.set$cluster.ids, method = "wilcoxon")
#do same processing on all_class_markers as done in pairwise markers in FindMarkerGenes function
all_class_markers %<>% dplyr::filter(foreground_mean > 1 |background_mean > 1) %>% dplyr::select(-background) %>% dplyr::distinct(feature, .keep_all = TRUE) %>% dplyr::mutate(log2_fc = log2(foreground_mean/background_mean))
#get log2fc, and select the top marker genes with the highest abs value log2fc
all_class_markers %<>% mutate(abs_log2_fc = log2(foreground_mean/background_mean) %>% abs()) %>% arrange(abs_log2_fc) %>% slice_max(abs_log2_fc, n = 10, by = foreground) %>% pull(feature)
# Create models
#normalize by reads_per_cell
train.set.all <- train.set.bp %>% t()

train.set.all <- multiply_cols(train.set.all, 1/Matrix::colSums(train.set.all))
# Log normalization
train.set.all <- log1p(train.set.all * 10000) 
#z-score
train.set.all <- train.set.all[,all_class_markers]
#get average expression and variance of each gene in log normalized space 
gene_level_stats <- matrix_stats(train.set.all, col_stats = "variance")$col_stats
avg_log_exp <-  gene_level_stats["mean",]
#get stdev of each gene
stdev <- gene_level_stats["variance",] %>% sqrt()
#z-score dataset
train.set.all <- train.set.all %>% add_cols(-avg_log_exp) %>% multiply_cols(1/stdev)
#pca w/top 20 PCs, unlike 3 in pairwise
marker_ge_pca <- prcomp(train.set.all, center = F, rank = 20)

#create rf on upsampled dataset
#make all classes have same probability, to better balance/better similarity to pairwise method
train.set.upsampled <- marker_ge_pca$x %>% as.matrix()
train.set.upsampled <- upSample(x = train.set.upsampled, y = annotations.train.set$cluster.ids %>% as.factor(), yname = "celltype_labels", list = T)
celltype_labels <- train.set.upsampled[["y"]]
reference_dataset <- train.set.upsampled[["x"]] %>% as.matrix()
one_v_all_model <- cv.glmnet(x = reference_dataset, y = celltype_labels, family = "multinomial", alpha = .5) #can try grouped and not grouped
#perform same transformations on test set, and z-score using train set m + sd
test.set.all <- test.set.bp %>% t()

test.set.all <- multiply_cols(test.set.all, 1/Matrix::colSums(test.set.all))
# Log normalization
test.set.all <- log1p(test.set.all * 10000) 
#z-score using train set mean + stdev for everything
test.set.all <- test.set.all[,all_class_markers]
test.set.all <- test.set.all %>%
        add_cols(-avg_log_exp) %>%
        multiply_cols(1 / stdev)
pc_loadings <- marker_ge_pca$rotation
# transform data using matrix multiplication operator %*%
test.set.all <- test.set.all %*% pc_loadings
test.set.all <- test.set.all %>% as.matrix()
predicted.classifications.all <- predict(one_v_all_model, test.set.all, s = "lambda.1se", type = "class") %>% as.character() %>% set_names(rownames(nonsparse_mat)) 
proportion_accurate_multi <- which(predicted.classifications.all == ground_truth_cluster_ids) %>% length() / length(ground_truth_cluster_ids)
proportion_accurate_multi
```
Looked like for cv.glmnet it worked fine with or without the thing (.92 vs .9, no difference)